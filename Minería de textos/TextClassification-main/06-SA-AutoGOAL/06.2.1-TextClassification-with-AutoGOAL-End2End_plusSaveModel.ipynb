{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06-TextClassification-with-AutoGOAL-End2End.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 32-bit",
      "name": "python38232bit8e64cf26f5654fd299a54afbe21440a3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "metadata": {
      "interpreter": {
        "hash": "e59aae061dfc42512350a05cb952bfa461a40b32b8014484151b92df146f5fa3"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeachingTextMining/TextClassification/blob/main/06-SA-AutoGOAL/06.2.1-TextClassification-with-AutoGOAL-End2End_plusSaveModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76GWp3TtCltu"
      },
      "source": [
        "## Clasificación de textos utilizando AutoML\n",
        "\n",
        "\n",
        "La clasificación de textos consiste en, dado un texto, asignarle una entre varias categorías. Algunos ejemplos de esta tarea son:\n",
        "\n",
        "- dado un tweet, categorizar su connotación como positiva, negativa o neutra.\n",
        "- dado un post de Facebook, clasificarlo como portador de un lenguaje ofensivo o no.  \n",
        "\n",
        "En la actividad exploraremos cómo utilizar la librería [AutoGOAL](https://github.com/autogoal/autogoal) para obtener una solución end-to-end a esta tarea y su aplicación para clasificar reviews de [IMDB](https://www.imdb.com/) sobre películas en las categorías \\[$positive$, $negative$\\]. \n",
        "\n",
        "\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "- siga las indicaciones y comentarios en cada apartado.\n",
        "\n",
        "\n",
        "**Después de esta actividad nos habremos familiarizado con:**\n",
        "- cómo modelar un problema de clasificación con AutoGOAL\n",
        "- cómo utilizar AutoGOAL para buscar automáticamente un *pipeline* para clasificación de textos.\n",
        "- utilizar este *pipeline* para clasificar nuevos textos.\n",
        "\n",
        "**Requerimientos**\n",
        "- python 3.6.12 - 3.8\n",
        "- tensorflow==2.3.0\n",
        "- autogoal==0.4.4\n",
        "- pandas==1.1.5\n",
        "- plotly==4.13.0\n",
        "- tqdm==4.56.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs8-IuHAWhw2"
      },
      "source": [
        "<a name=\"sec:setup\"></a>\n",
        "### Instalación de librerías e importación de dependencias.\n",
        "\n",
        "Para comenzar, es preciso instalar e incluir las librerías necesarias. En este caso, el entorno de Colab incluye las necesarias.\n",
        "\n",
        "Ejecute la siguiente casilla prestando atención a las explicaciones dadas en los comentarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxub5L7JWiIl"
      },
      "source": [
        "# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n",
        "# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrarían ya instaladas\n",
        "%%capture\n",
        "!pip install autogoal[contrib]==0.4.4\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tceeXqX5tIWB"
      },
      "source": [
        "# temporal cell, just to test AutoGOAL install...\n",
        "%%capture \n",
        "#!python -m site\n",
        "#!ls /usr/local/lib/python3.7/dist-packages\n",
        "#!pip install rich\n",
        "#!unzip autogoal.zip\n",
        "#!mv /usr/local/lib/python3.7/dist-packages/autogoal/ /usr/local/lib/python3.7/dist-packages/autogoal.bak\n",
        "#!cp -r autogoal /usr/local/lib/python3.7/dist-packages/\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga7lVYFMCltv"
      },
      "source": [
        "# reset environment\n",
        "%reset -f\n",
        "\n",
        "#  para construir gráficas y realizar análisis exploratorio de los datos\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "\n",
        "# para cargar datos y realizar pre-procesamiento básico\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# para evaluar los modelos \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, f1_score\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "# para configurar AutoGOAL\n",
        "from autogoal.ml import AutoML\n",
        "from autogoal.search import (Logger, PESearch, ConsoleLogger, ProgressLogger, MemoryLogger)\n",
        "from autogoal.kb import Seq, Sentence, VectorCategorical, Supervised\n",
        "from autogoal.contrib import find_classes\n",
        "\n",
        "# para guardar el modelo\n",
        "import pickle\n",
        "import datetime\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvCAcoPfntwB"
      },
      "source": [
        "#### Definición de funciones y variables necesarias para el pre-procesamiento de datos\n",
        "\n",
        "Antes de definir el pipeline definiremos algunas variables útiles como el listado de stop words y funciones para cargar los datos, entrenar el modelo etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jvtD8EWoA-p"
      },
      "source": [
        "# función auxiliar para realizar predicciones con el modelo\n",
        "def predict_model(model, cfg, data, pref='m'):\n",
        "  \"\"\"\n",
        "  data: list of the text to predict\n",
        "  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\n",
        "  \"\"\"\n",
        "  res = {}\n",
        "  scores = None\n",
        "\n",
        "  labels = model.predict(data)\n",
        "\n",
        "  if hasattr(model, 'predict_proba'):\n",
        "    scores = model.predict_proba(data)\n",
        "  \n",
        "    # empaquetar scores dentro de un diccionario que contiene labels, scores clase 1, scores clase 2, .... El nombre de la clase se normaliza a lowercase\n",
        "    res = {f'scores_{pref}_{cls.lower()}':score for cls, score in zip(model.classes_, [col for col in scores.T])}\n",
        "\n",
        "  # añadir datos relativos a la predicción\n",
        "  res[f'labels_{pref}'] = cfg['label_encoder'].inverse_transform(labels)\n",
        "\n",
        "  # convertir a dataframe ordenando las columnas primero el label y luego los scores por clase, las clases ordenadas alfabeticamente.\n",
        "  res = pd.DataFrame(res, columns=sorted(list(res.keys())))\n",
        "\n",
        "  return res\n",
        "\n",
        "\n",
        "# función auxiliar que evalúa los resultados de una clasificación\n",
        "def evaluate_model(y_true, y_pred, y_score=None, pos_label='positive'):\n",
        "  \"\"\"\n",
        "  data: list of the text to predict\n",
        "  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\n",
        "  \"\"\"\n",
        "  print('==== Sumario de la clasificación ==== ')\n",
        "  print(classification_report(y_true, y_pred))\n",
        "\n",
        "  print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_true, y_pred)))\n",
        "\n",
        "  # graficar matriz de confusión\n",
        "  display_labels = sorted(unique_labels(y_true, y_pred), reverse=True)\n",
        "  cm = confusion_matrix(y_true, y_pred, labels=display_labels)\n",
        "\n",
        "  z = cm[::-1]\n",
        "  x = display_labels\n",
        "  y =  x[::-1].copy()\n",
        "  z_text = [[str(y) for y in x] for x in z]\n",
        "\n",
        "  fig_cm = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n",
        "\n",
        "  fig_cm.update_layout(\n",
        "      height=400, width=400,\n",
        "      showlegend=True,\n",
        "      margin={'t':150, 'l':0},\n",
        "      title={'text' : 'Matriz de Confusión', 'x':0.5, 'xanchor': 'center'},\n",
        "      xaxis = {'title_text':'Valor Real', 'tickangle':45, 'side':'top'},\n",
        "      yaxis = {'title_text':'Valor Predicho', 'tickmode':'linear'},\n",
        "  )\n",
        "  fig_cm.show()\n",
        "\n",
        "\n",
        "  # curva roc (definido para clasificación binaria)\n",
        "  fig_roc = None\n",
        "  if y_score is not None:\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=pos_label)\n",
        "    fig_roc = px.area(\n",
        "        x=fpr, y=tpr,\n",
        "        title = f'Curva ROC (AUC={auc(fpr, tpr):.4f})',\n",
        "        labels=dict(x='Ratio Falsos Positivos', y='Ratio Verdaderos Positivos'),\n",
        "        width=400, height=400\n",
        "    )\n",
        "    fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n",
        "\n",
        "    fig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "    fig_roc.update_xaxes(constrain='domain')\n",
        "    \n",
        "    fig_roc.show()\n",
        "\n",
        "\n",
        "# custom logger\n",
        "# - imprime y guarda el mejor pipeline cada vez que se encuentre una nueva solución candidad\n",
        "# - imprime pipelines cuya evaluación falló\n",
        "class CustomLogger(Logger):\n",
        "    def __init__(self, classifier, save_model=True, check_folder=\".\"):\n",
        "        self.save_model = save_model\n",
        "        self.check_folder = check_folder\n",
        "        self.classifier = classifier\n",
        "\n",
        "    def error(self, e: Exception, solution):\n",
        "        if e and solution:\n",
        "            with open(\"reviews_errors.log\", \"a\") as fp:\n",
        "                fp.write(f\"solution={repr(solution)}\\nerror={repr(e)}\\n\\n\")\n",
        "\n",
        "    def update_best(self, new_best, new_fn, *args):\n",
        "        pipecode = datetime.datetime.now(datetime.timezone.utc).strftime(\"reviews--%Y-%m-%d--%H-%M-%S--{0}\".format(hex(id(new_best))))\n",
        "        with open(\"reviews_update_best.log\", \"a\") as fp:\n",
        "            fp.write(f\"\\n{pipecode}\\nsolution={repr(new_best)}\\nfitness={new_fn}\\n\\n\")\n",
        "\n",
        "        if(self.save_model):\n",
        "            fp = open('{1}.pkl'.format(self.check_folder,pipecode), 'wb')\n",
        "            new_best.sampler_.replay().save(fp)\n",
        "            pickle.Pickler(fp).dump((self.classifier.input, self.classifier.output))\n",
        "            fp.close()\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me0P5d8PoHFo"
      },
      "source": [
        "<a name=\"sec:load-data\"></a>\n",
        "### Carga de datos y análisis exploratorio\n",
        "\n",
        "Antes de entrenar el pipeline, es necesario cargar los datos. Existen diferentes opciones, entre estas:\n",
        "\n",
        "- montar nuestra partición de Google Drive y leer un fichero desde esta.\n",
        "\n",
        "- leer los datos desde un fichero en una carpeta local.\n",
        "\n",
        "- leer los datos directamente de un URL.\n",
        "\n",
        "Ejecute la siguiente casilla prestando atención a las instrucciones adicionales en los comentarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg6pvcsVoHZ4"
      },
      "source": [
        "# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n",
        "\n",
        "# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n",
        "#path = './sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "# descomente la siguiente línea para leer datos desde un URL\n",
        "path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/06-SA-AutoGOAL/sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "# leer los datos\n",
        "data = pd.read_csv(path, sep=',')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suEnoVDuoMvZ"
      },
      "source": [
        "Una vez leídos los datos, ejecute la siguiente casilla para construir una gráfica que muestra la distribución de clases en el corpus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQG6uQTNoNIY"
      },
      "source": [
        "text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\n",
        "class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\n",
        "\n",
        "# obtener algunas estadísticas sobre los datos\n",
        "categories = sorted(data[class_col].unique(), reverse=False)\n",
        "hist= Counter(data[class_col]) \n",
        "print(f'Total de instancias -> {data.shape[0]}')\n",
        "print(f'Distribución de clases -> {{item[0]:round(item[1]/len(data[class_col]), 3) for item in sorted(hist.items(), key=lambda x: x[0])}}')\n",
        "\n",
        "print(f'Categorías -> {categories}')\n",
        "print(f'Comentario de ejemplo -> {data[text_col][0]}')\n",
        "print(f'Categoría del comentario -> {data[class_col][0]}')\n",
        "\n",
        "fig = go.Figure(layout=go.Layout(height=400, width=600))\n",
        "fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in categories]))\n",
        "fig.show()\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-_EGWESoRsA"
      },
      "source": [
        "Finalmente, ejecute la siguiente casilla para crear los conjuntos de entrenamiento y validación que se utilizarán para entrenar y validar los modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLK_nyK1oSAP"
      },
      "source": [
        "# obtener conjuntos de entrenamiento (90%) y validación (10%)\n",
        "seed = 0  # fijar random_state para reproducibilidad\n",
        "train, val = train_test_split(data, test_size=.1, stratify=data[class_col], random_state=seed)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQB9gdvrokzJ"
      },
      "source": [
        "### Implementación y configuración del modelo\n",
        "\n",
        "Con AutoGOAL podemos configurar el modelo facilmente pues solo necesitamos instanciar la clase AutomML. Lo más importante es elegir los tipos adecuados para datos de entrada y salida en nuestro modelo y la métrica de evaluación. En este caso:\n",
        "\n",
        "- entrada (input), una tupla de:\n",
        "    - Seq(Sentence()) -> una lista (Seq) con cada una de las instancias (Sentence)\n",
        "    - Supervised[VectorCategorical]) -> indica se trata de aprendizaje supervisado.\n",
        "    \n",
        "- salida (output): VectorCategorical -> el elemento *i* representa la categoría asociada a la instancia *i*.\n",
        "\n",
        "Ejecute la siguiente casilla prestando atención a los comentarios adicionales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZoQNW4PClt4"
      },
      "source": [
        "# configuraciones\n",
        "cfg = {}\n",
        "cfg['iterations'] = 1 # cantidad de iteraciones a realizar\n",
        "cfg['popsize'] = 50  # tamaño de la población\n",
        "cfg['search_timeout'] = 120  # tiempo máximo de búsqueda en segundos\n",
        "cfg['evaluation_timeout'] = 60  # tiempo máximo que empleará evaluando un pipeline en segundos\n",
        "cfg['memory'] = 20  # cantidad máxima de memoria a utilizar\n",
        "cfg['score_metric'] = f1_score  # métrica de evaluación\n",
        "\n",
        "search_kwargs=dict(\n",
        "    pop_size=cfg['popsize'],\n",
        "    search_timeout=cfg['search_timeout'],\n",
        "    evaluation_timeout=cfg['evaluation_timeout'],\n",
        "    memory_limit=cfg['memory'] * 1024 ** 3,\n",
        ")\n",
        "\n",
        "model = AutoML(\n",
        "    input=(Seq[Sentence], Supervised[VectorCategorical]),  # tipo datos de entrada\n",
        "    output=VectorCategorical,  # tipo datos de salida\n",
        "    \n",
        "    score_metric=cfg['score_metric'],\n",
        "    search_algorithm=PESearch,  # algoritmo de búsqueda\n",
        "    registry=None,  # para incluir clases adicionales \n",
        "    \n",
        "    search_iterations=cfg['iterations'],\n",
        "    \n",
        "    include_filter=\".*\",  # indica qué módulos pueden incluirse en los pipelines evaluados\n",
        "    exclude_filter=None,  # indica módulos a excluir de los pipelines evaluados\n",
        "    \n",
        "    validation_split=0.3,  # porción de los datos de entrenamiento que AutoGOAL tomará para evaluar cada pipeline\n",
        "    cross_validation_steps=3,  # cantidad de particiones en la crossvalidación\n",
        "    cross_validation=\"mean\",  # tipo de agregación para los valores de la métrica en cada partición de la crossvalidación (promedio, mediana, etc.)\n",
        "    \n",
        "    random_state=None,  # semilla para el generador de números aleatorios\n",
        "    errors=\"warn\",  # tratamiento ante errores\n",
        "    **search_kwargs\n",
        ")\n",
        "\n",
        "# configurar loggers\n",
        "loggers = [ProgressLogger(), ConsoleLogger(), MemoryLogger(), CustomLogger(model, save_model=True, check_folder=\".\")]\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRRPI2CzOCOo"
      },
      "source": [
        "<a name=\"sec:pre-proc\"></a>\n",
        "### Pre-procesamiento de los datos\n",
        "\n",
        "\n",
        "Notar que en este caso AutoGOAL trabajará directamente con el texto, decidiendo si aplica algún algoritmo de extracción de rasgos o pre-procesamiento. En este caso, solo necesitaremos codificar las categorías como números utilizando [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) de [scikit-learn](https://scikit-learn.org/stable/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvGYkhf1vhs_"
      },
      "source": [
        "#### Instanciar LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPE4kSXVvOUa"
      },
      "source": [
        "# instanciar LabelEncoder\n",
        "cfg['label_encoder'] = LabelEncoder()\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUVaVHUjvp2b"
      },
      "source": [
        "#### Pre-procesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfrzCUr9u3pn"
      },
      "source": [
        "# entrenar LabelEncoder\n",
        "cfg['label_encoder'].fit(train[class_col])\n",
        "\n",
        "# guardar LabelEncoder entrenado para su posterior uso (codificar nuevos datos).\n",
        "with open('label_encoder_reviews.pkl', 'wb') as f:\n",
        "    pickle.dump(cfg['label_encoder'], f)\n",
        "\n",
        "# codificar labels\n",
        "train_labels = cfg['label_encoder'].transform(train[class_col])\n",
        "val_labels = cfg['label_encoder'].transform(val[class_col])\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rn4Poq2R4UX"
      },
      "source": [
        "### Entrenamiento del modelo\n",
        "\n",
        "Por último es necesario \"entrenar el modelo\", que en este caso significa iniciar la búsqueda.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J2Rf7dvXh7m"
      },
      "source": [
        "model.fit(train[text_col].to_list(), train_labels, logger=loggers)\n",
        "\n",
        "print(model.best_pipeline_)\n",
        "print(model.best_score_)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLh4KHHgX_bw"
      },
      "source": [
        "Finalmente, guardamos el modelo, este contendrá el mejor pipeline encontrado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBnxcf0WSj4h"
      },
      "source": [
        "with open('model_reviews.pkl', 'wb') as f:\n",
        "    model.save(f)\n",
        "    \n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_9A1ZkyfCq4"
      },
      "source": [
        "### Evaluación del modelo\n",
        "Luego de entrenado el modelo, podemos evaluar su desempeño en los conjuntos de entrenamiento y validación.\n",
        "\n",
        "Ejecute la siguiente casilla para evaluar el modelo en el conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh_wgiOfXOWZ"
      },
      "source": [
        "# predecir y evaluar el modelo en el conjunto de entrenamiento\n",
        "print('==== Evaluación conjunto de entrenamiento ====')\n",
        "data = train\n",
        "true_labels = data[class_col]\n",
        "\n",
        "m_pred = predict_model(model, cfg, data[text_col].to_list(), pref='m')\n",
        "\n",
        "# el nombre de los campos dependerá de pref al llamar a predic_model y las clas|es. Ver comentarios en la definición de la función\n",
        "evaluate_model(true_labels, m_pred['labels_m'])  \n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2hZlaFL7omz"
      },
      "source": [
        "Ejecute la siguiente casilla para evaluar el modelo en el conjunto de validación. Compare los resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1vinOtO7o-h"
      },
      "source": [
        "# predecir y evaluar el modelo en el conjunto de validación\n",
        "print('==== Evaluación conjunto de validacióm ====')\n",
        "data = val\n",
        "true_labels = data[class_col]\n",
        "\n",
        "m_pred = predict_model(model, cfg, data[text_col].to_list(), pref='m')\n",
        "\n",
        "# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\n",
        "evaluate_model(true_labels, m_pred['labels_m'])  \n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-jAoCZGPqCj"
      },
      "source": [
        "## Predicción de nuevos datos\n",
        "\n",
        "Una vez entrenado el modelo, podemos evaluar su rendimiento en datos no utilizados durante el entrenamiento o emplearlo para predecir nuevas instancias. En cualquier caso, se debe cuidar realizar los pasos de pre-procesamiento necesarios según el caso. En el ejemplo, utilizaremos la porción de prueba preparada inicialmente.\n",
        "\n",
        "**Notar que**:\n",
        "-  se cargará el modelo previamente entrenado y guardado, estableciendo las configuraciones pertinentes.\n",
        "\n",
        "- si disponemos de un modelo guardado, podremos ejecutar directamente esta parte del cuaderno. Sin embargo, será necesario al menos ejecutar previamente la sección [Instalación de librerías...](#sec:setup)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G9robk3wcRp"
      },
      "source": [
        "### Cargar otros elementos necesarios \n",
        "\n",
        "Antes de predecir nuevos datos, también es preciso cargar otros elementos necesarios como el codificador para las etiquetas, etc.\n",
        "\n",
        "Ejecute la siguiente casilla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DriOyJkbbd5"
      },
      "source": [
        "# configuraciones\n",
        "text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\n",
        "class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\n",
        "\n",
        "cfg = {}  # diccionario para agrupar configuraciones y variables para su posterior uso\n",
        "\n",
        "# cargar el LabelEncoder\n",
        "with open('label_encoder_reviews.pkl', 'rb') as f:\n",
        "    cfg['label_encoder'] = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Fmkq3BPyvf"
      },
      "source": [
        "### Instanciar modelo pre-entrenado\n",
        "\n",
        "Para predecir nuevas instancias es preciso cargar el modelo previamente entrenado.\n",
        "\n",
        "Ejecute la siguiente casilla para cargar el pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcFQIegh7p-a"
      },
      "source": [
        "# cargar mejor pipeline\n",
        "model = None\n",
        "with open('model_reviews.pkl', 'rb') as f:\n",
        "    model = AutoML.load(f)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDtF-ZzAa6Ev"
      },
      "source": [
        "### Leer datos de entrenamiento y pre-procesarlos\n",
        "Antes de entrenar el modelo, debemos leer los datos de entrenamiento. Podemos recordar los detalles de [Pre-procesamiento de los datos](#sec:pre-proc).\n",
        "\n",
        "Ejecute las siguientes casillas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7hXySFZY2N5"
      },
      "source": [
        "# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n",
        "\n",
        "# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n",
        "#path = './sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "# descomente la siguiente línea para leer datos desde un URL\n",
        "path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/06-SA-AutoGOAL/sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "# leer los datos\n",
        "data = pd.read_csv(path, sep=',')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wkEux6ld0jP"
      },
      "source": [
        "### Entrenar mejor pipeline\n",
        "En este caso, podemos entrenar con todos los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIjPl10Md2WI"
      },
      "source": [
        "# codificar labels\n",
        "train_labels = cfg['label_encoder'].transform(data[class_col])\n",
        "\n",
        "model.fit_pipeline(data[text_col].to_list(), train_labels)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H4me-h3eJLh"
      },
      "source": [
        "### Predecir nuevos datos\n",
        "\n",
        "Con el modelo cargado, es posible utilizarlo para analizar nuevos datos. \n",
        "\n",
        "Ejecute las siguientes casillas para:\n",
        "\n",
        "(a) categorizar un texto de muestra.\n",
        "\n",
        "(b) cargar nuevos datos, categorizarlos y mostrar algunas estadísticas sobre el corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njoBIOJ-d-yg"
      },
      "source": [
        "# ejemplo de texto a clasificar en formato [text 1, text 2, ..., text n]\n",
        "text = ['Brian De Palma\\'s undeniable virtuosity can\\'t really camouflage the fact that his plot here is a thinly disguised\\\n",
        "        \\\"Psycho\\\" carbon copy, but he does provide a genuinely terrifying climax. His \"Blow Out\", made the next year, was an improvement.']\n",
        "\n",
        "# predecir los nuevos datos.\n",
        "m_pred = predict_model(model, cfg, text, pref='m')\n",
        "\n",
        "# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\n",
        "pred_labels = m_pred['labels_m'].values[0]\n",
        "\n",
        "print(f'La categoría del review es -> {pred_labels}')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soc1PQnEeZon"
      },
      "source": [
        "También podemos predecir nuevos datos cargados desde un fichero. \n",
        "\n",
        "Ejecute la siguiente casilla, descomentando las instrucciones necesarias según sea el caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz8QkhPeeTlX"
      },
      "source": [
        "# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n",
        "\n",
        "# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n",
        "#path = './sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "# descomente la siguiente línea para leer datos desde un URL\n",
        "path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/01-SA-Pipeline/sample_data/ejemplo_review_test.csv'\n",
        "\n",
        "# leer los datos\n",
        "new_data = pd.read_csv(path, sep=',')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UTCvP3QecrH"
      },
      "source": [
        "Ejecute la siguiente celda para predecir los datos y mostrar algunas estadísticas sobre el análisis realizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VGbyGdRebLH"
      },
      "source": [
        "# predecir los datos de prueba\n",
        "m_pred = predict_model(model, cfg, new_data[text_col].to_list(), pref='m')\n",
        "pred_labels = m_pred['labels_m']\n",
        "\n",
        "# obtener algunas estadísticas sobre la predicción en el conjunto de pruebas\n",
        "categories = sorted(pred_labels.unique(), reverse=False)\n",
        "hist = Counter(pred_labels.values) \n",
        "\n",
        "fig = go.Figure(layout=go.Layout(height=400, width=600))\n",
        "fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in categories]))\n",
        "fig.show()\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfWPYGwyefkH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
