{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeachingTextMining/TextClassification/blob/main/02-SA-Transformers-Basic/02-TextClassification-with-Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76GWp3TtCltu"
      },
      "source": [
        "## Clasificación de textos utilizando Transformers\n",
        "\n",
        "La clasificación de textos consiste en, dado un texto, asignarle una entre varias categorías. Algunos ejemplos de esta tarea son:\n",
        "\n",
        "- dado un tweet, categorizar su connotación como positiva, negativa o neutra.\n",
        "- dado un post de Facebook, clasificarlo como portador de un lenguaje ofensivo o no.  \n",
        "\n",
        "En la actividad exploraremos cómo utilizar soluciones *out of the box* para esta tarea incluidas en la librería [Transformers](https://huggingface.co/transformers/) y su aplicación para clasificar reviews de [IMDB](https://www.imdb.com/) sobre películas en las categorías \\[$positive$, $negative$\\]. \n",
        "\n",
        "Puede encontrar más información sobre este problema en [Kaggle](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) y en [Large Movie Review Datase](http://ai.stanford.edu/~amaas/data/sentiment/).\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "- siga las indicaciones y comentarios en cada apartado.\n",
        "\n",
        "\n",
        "**Después de esta actividad nos habremos familiarizado con:**\n",
        "- seleccionar e instanciar modelos pre-entrenados para realizar clasificación de textos.\n",
        "- cómo instanciar un pipeline para la clasificación de textos utilizando la librería Transformers.\n",
        "- utilizar este pipeline para clasificar nuevos textos.\n",
        "\n",
        "**Requerimientos**\n",
        "- python 3.6.12 - 3.8\n",
        "- transformers==4.26.0\n",
        "- tensorflow==2.11\n",
        "- pandas==1.3.5\n",
        "- plotly==5.5.0\n",
        "- scikit-learn==1.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs8-IuHAWhw2"
      },
      "source": [
        "<a name=\"sec:setup\"></a>\n",
        "### Instalación de librerías e importación de dependencias.\n",
        "\n",
        "Para comenzar, es preciso instalar las dependencias, realizar los imports necesarios y definir algunas funciones auxiliares.\n",
        "\n",
        "Ejecute las siguientes casillas prestando atención a las instrucciones adicionales en los comentarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxub5L7JWiIl"
      },
      "source": [
        "# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n",
        "# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrarían ya instaladas\n",
        "%%capture\n",
        "!pip install transformers==4.26.0 tensorflow==2.11 pandas==1.3.5 plotly==5.5.0 scikit-learn==1.0.0\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga7lVYFMCltv"
      },
      "source": [
        "# reset environment\n",
        "%reset -f\n",
        "\n",
        "# para cargar datos y realizar pre-procesamiento básico\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# para evaluar los modelos \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "# para construir gráficas y realizar análisis exploratorio de los datos\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "from tqdm import tqdm\n",
        "\n",
        "# algoritmos de clasificación, tokenizadores, etc.\n",
        "from transformers import TextClassificationPipeline, DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "\n",
        "from transformers.tokenization_utils import TruncationStrategy\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izFoCjN-hnfS"
      },
      "source": [
        "# función auxiliar para realizar predicciones con el modelo\n",
        "def predict_model(model, cfg, data, batch_size=128, pref='m'):\n",
        "  \"\"\"\n",
        "  data: list of the text to predict\n",
        "  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\n",
        "  \"\"\"\n",
        "  res = {}\n",
        "  size = len(data)\n",
        "  res_dic = {}\n",
        "\n",
        "  for i in tqdm(range(0, size, batch_size)):\n",
        "      batch_text = data[i:i+batch_size]\n",
        "      results = model(batch_text, truncation=cfg['truncation'])\n",
        "      # formatear la salida que para cada instancia es una lista tipo con un diccionario para cada clase, con llaves label, score. \n",
        "      # por ejemplo, para tres clases [{'label':'NEUTRAL', 'score':0.5}, {'label':'NEGATIVE', 'score':0.1}, {'label':'POSITIVE', 'score':0.4}]\n",
        "      for inst in results:\n",
        "        for cat in inst:\n",
        "          cn = f'scores_{pref}_{cat[\"label\"].lower()}' \n",
        "          if cn in res_dic.keys():\n",
        "            res_dic[cn].append(cat['score'])\n",
        "          else:\n",
        "            res_dic[cn] = list([cat['score']])\n",
        "\n",
        "  res = pd.DataFrame(res_dic, columns=sorted(list(res_dic.keys())))\n",
        "  res[f'labels_{pref}'] = res.idxmax(axis=1).apply(lambda n: n.split('_')[2])  # label = categoría con mayor probabilidad\n",
        "  res = res.reindex(columns=sorted(res.columns))\n",
        "  return res\n",
        "\n",
        "\n",
        "# función auxiliar que evalúa los resultados de una clasificación\n",
        "def evaluate_model(y_true, y_pred, y_score=None, pos_label='positive'):\n",
        "\n",
        "  print('==== Sumario de la clasificación ==== ')\n",
        "  print(classification_report(y_true, y_pred))\n",
        "\n",
        "  print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_true, y_pred)))\n",
        "\n",
        "  # graficar matriz de confusión\n",
        "  display_labels = sorted(unique_labels(y_true, y_pred), reverse=True)\n",
        "  cm = confusion_matrix(y_true, y_pred, labels=display_labels)\n",
        "\n",
        "  z = cm[::-1]\n",
        "  x = display_labels\n",
        "  y =  x[::-1].copy()\n",
        "  z_text = [[str(y) for y in x] for x in z]\n",
        "\n",
        "  fig_cm = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n",
        "\n",
        "  fig_cm.update_layout(\n",
        "      height=400, width=400,\n",
        "      showlegend=True,\n",
        "      margin={'t':150, 'l':0},\n",
        "      title={'text' : 'Matriz de Confusión', 'x':0.5, 'y':0.95, 'xanchor': 'center'},\n",
        "      xaxis = {'title_text':'Valor Real', 'tickangle':45, 'side':'top'},\n",
        "      yaxis = {'title_text':'Valor Predicho', 'tickmode':'linear'},\n",
        "  )\n",
        "  fig_cm.show()\n",
        "\n",
        "\n",
        "  # curva roc (definido para clasificación binaria)\n",
        "  fig_roc = None\n",
        "  if y_score is not None:\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=pos_label)\n",
        "    fig_roc = px.area(\n",
        "        x=fpr, y=tpr,\n",
        "        title = f'Curva ROC (AUC={auc(fpr, tpr):.4f})',\n",
        "        labels=dict(x='Ratio Falsos Positivos', y='Ratio Verdaderos Positivos'),\n",
        "        width=400, height=400\n",
        "    )\n",
        "    fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n",
        "\n",
        "    fig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "    fig_roc.update_xaxes(constrain='domain')\n",
        "    \n",
        "    fig_roc.show()\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByEBYoR3hqzw"
      },
      "source": [
        "### Carga de datos y análisis exploratorio\n",
        "\n",
        "El primer paso consiste en obtener los datos relacionados con nuestra tarea dejándolos en el formato adecuado.  Existen diferentes opciones, entre estas:\n",
        "\n",
        "- montar nuestra partición de Google Drive y leer un fichero desde esta.\n",
        "\n",
        "- leer los datos desde un fichero en una carpeta local.\n",
        "\n",
        "- leer los datos directamente de un URL.\n",
        "\n",
        "En este caso, se encuentran en un fichero separado por comas con la siguiente estructura:\n",
        "\n",
        "| Phrase | Sentiment| \n",
        "| ------ | ------ |\n",
        "| This movie is really not all that bad...    | positive |\n",
        "\n",
        "\n",
        "Ejecute la siguiente casilla para leer los datos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTBmYxkBhunP"
      },
      "source": [
        "# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n",
        "\n",
        "# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n",
        "#path = './sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "# descomente la siguiente línea para leer datos desde un URL\n",
        "path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/01-SA-Pipeline/sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "# leer los datos\n",
        "data = pd.read_csv(path, sep=',')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiZ1Tf4Dh6k3"
      },
      "source": [
        "Una vez leídos los datos, ejecute la siguiente casilla para construir una gráfica que muestra la distribución de clases en el corpus.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1c5ZREAh7Y_"
      },
      "source": [
        "text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\n",
        "class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\n",
        "\n",
        "# obtener algunas estadísticas sobre los datos\n",
        "categories = sorted(data[class_col].unique(), reverse=False)\n",
        "hist= Counter(data[class_col]) \n",
        "print(f'Total de instancias -> {data.shape[0]}')\n",
        "print('Distribución de clases:')\n",
        "for item in sorted(hist.items(), key=lambda x: x[0]): print(f'    {item[0]}: {round(item[1]/len(data[class_col]), 3)}')\n",
        "\n",
        "print(f'Categorías -> {categories}')\n",
        "print(f'Comentario de ejemplo -> {data[text_col][0]}')\n",
        "print(f'Categoría del comentario -> {data[class_col][0]}')\n",
        "\n",
        "fig = go.Figure(layout=go.Layout(height=400, width=600))\n",
        "fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in categories]))\n",
        "fig.show()\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi8kqy5hIQFh"
      },
      "source": [
        "Finalmente, ejecute la siguiente casilla para crear los conjuntos de entrenamiento y validación que se utilizarán para entrenar y validar los modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww5Dm4UPIQzh"
      },
      "source": [
        "# obtener conjuntos de entrenamiento (90%) y validación (10%)\n",
        "seed = 0  # fijar random_state para reproducibilidad\n",
        "train, val = train_test_split(data, test_size=.1, stratify=data[class_col], random_state=seed)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cA2HwMRClty"
      },
      "source": [
        "### Carga del modelo pre-entrenado\n",
        "La librería Transformers provee diferentes modelos listos para usar en la tarea de clasificación de textos. Una forma flexible de lograrlo consiste en:\n",
        "\n",
        "- seleccionar un modelo pre-entrenado adecuado para la tarea. Podemos examinar los modelos disponibles en [https://huggingface.co/models](https://huggingface.co/models). Estaremos utilizando el llamado [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) que permite clasificar un texto en idioma inglés de acuerdo con su connotación **positiva** o **negativa**.\n",
        "\n",
        "- instanciar el modelo y su correspondiente tokenizador.\n",
        "\n",
        "- crear un pipeline para la clasificación de textos, en este caso utilizando la clase [TextClassificationPipeline](https://huggingface.co/transformers/main_classes/pipelines.html#transformers.TextClassificationPipeline).\n",
        "\n",
        "- utilizar el pipeline para clasificar textos.\n",
        "\n",
        "\n",
        "Ejecute la siguiente celda para instanciar el modelo y el correspondiente tokenizador.\n",
        "\n",
        "**Note que:**\n",
        "- la práctica recomendada al crear un nuevo modelo para Transformers es hacerlo disponible mediante un fichero que contiene los elementos necesarios para su posterior uso, como son el modelo, el tokenizador y una tarjeta con metadatos sobre el modelo. \n",
        "\n",
        "- es conveniente indagar sobre el modelo base utilizado, en este caso **DistilBert**, esto permitirá seleccionar las clases adecuadas para instanciar el modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozSej98kCltz"
      },
      "source": [
        "# configuraciones\n",
        "cfg = {} # diccionario para organizar los objetos que son parámetros del modelo, etc.\n",
        "cfg['framework'] = 'tf'\n",
        "cfg['task'] = 'sentiment-analysis'\n",
        "cfg['trained_model_name'] = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
        "cfg['max_length'] = 512  # máxima longitud de secuencia recomendada por DistilBERT\n",
        "cfg['truncation'] = TruncationStrategy.ONLY_FIRST\n",
        "\n",
        "# cargar el tokenizador, disponible en Transformers. Establecer model_max_length para cuando el tokenizador sea llamado, trunque automáticamente.\n",
        "cfg['tokenizer'] = DistilBertTokenizer.from_pretrained(cfg['trained_model_name'] , model_max_length=cfg['max_length'])\n",
        "\n",
        "# cargar el modelo, disponible en Transformers\n",
        "cfg['transformer'] = TFDistilBertForSequenceClassification.from_pretrained(cfg['trained_model_name'])\n",
        "\n",
        "# instanciar el pipeline para la clasificación de textos\n",
        "model = TextClassificationPipeline(model=cfg['transformer'], tokenizer=cfg['tokenizer'], framework=cfg['framework'], task=cfg['task'], top_k=None)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvWMQ9x4Clt4"
      },
      "source": [
        "Ejecute la siguiente celda para clasificar una la frase. Alternativamente, puede modificar el texto incluyendo uno de su preferencia. Recuerde que debe ser en idioma inglés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZoQNW4PClt4"
      },
      "source": [
        "# ejemplo de texto a clasificar, # lista [texto 1, text 2, ..., texto n]\n",
        "text = ['Brian De Palma\\'s undeniable virtuosity can\\'t really camouflage the fact that his plot here is a thinly disguised\\\n",
        "        \\\"Psycho\\\" carbon copy, but he does provide a genuinely terrifying climax. His \"Blow Out\", made the next year, was an improvement.']\n",
        "\n",
        "m_pred = predict_model(model, cfg, text, pref='m' )\n",
        "\n",
        "# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\n",
        "pred_labels = m_pred['labels_m'].values[0]\n",
        "pred_proba = m_pred['scores_m_positive'].values[0]\n",
        "\n",
        "print(f'\\nLa categoría de la frase es -> {pred_labels}')\n",
        "print(f'El score asignado a la clase positiva es -> {pred_proba:.2f}')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX_NrA0NY7oP"
      },
      "source": [
        "### Evaluación del modelo\n",
        "\n",
        "En este caso no ha sido necesario entrenar el modelo, no obstante, lo evaluaremos en un conjunto reviews para los que se conoce su categoría de modo que podamos estimar el desempeño en nuevos datos.\n",
        "\n",
        "Ejecute la siguiente casilla para evaluar el modelo en la porción de validación separada previamente.\n",
        "\n",
        "**Notar que:**\n",
        "\n",
        "- la salida del modelo es un diccionario con 'label' y 'score'. Debemos formatearla para poder comparar con los valores de referencia.\n",
        "\n",
        "- para evitar problemas relacionados con el consumo de memoria, se realizará la predicción de instancias por lotes. Además, se utilizará TruncationStrategy.ONLY_FIRST para indicar al pipeline que trunque las secuencias con longitud mayor a la recomendada por el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptboGvWxiRqN"
      },
      "source": [
        "# predecir y evaluar conjunto de validación con el modelo\n",
        "data = val\n",
        "true_labels = data[class_col]\n",
        "\n",
        "m_pred = predict_model(model, cfg, data[text_col].to_list(), batch_size=128, pref='m')\n",
        "\n",
        "# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\n",
        "evaluate_model(true_labels, m_pred['labels_m'], m_pred['scores_m_positive'], 'positive')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj3fedYRClt6"
      },
      "source": [
        "### Predicción de nuevos datos\n",
        "Una vez evaluado el modelo para estimar su rendimiento en nuestro problema, podemos utilizarlo para predecir nuevos datos. En el ejemplo, utilizaremos la porción de prueba preparada inicialmente.\n",
        "\n",
        "Ejecute la siguiente casilla para cargar los datos, descomentando las instrucciones necesarias según sea el caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNb1SPTMClt7"
      },
      "source": [
        "# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n",
        "\n",
        "# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n",
        "#path = './sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "# descomente la siguiente línea para leer datos desde un URL\n",
        "path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/02-SA-Transformers-Basic/sample_data/ejemplo_review_test.csv'\n",
        "\n",
        "# leer los datos\n",
        "new_data = pd.read_csv(path, sep=',')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZTb-wbUClt9"
      },
      "source": [
        "Ejecute la siguiente celda para clasificar los textos. Tenga en cuenta que, en dependencia del entorno de ejecución, la cantidad de textos y su longitud, la ejecución puede tardar varios minutos o requerir una cantidad de memoria no disponible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nlsy-9IClt-"
      },
      "source": [
        "# predecir los datos de prueba\n",
        "m_pred = predict_model(model, cfg, new_data[text_col].to_list(), batch_size=128, pref='m')\n",
        "pred_labels = m_pred['labels_m']\n",
        "\n",
        "# obtener algunas estadísticas sobre la predicción en el conjunto de pruebas\n",
        "categories = sorted(pred_labels.unique(), reverse=True)\n",
        "hist = Counter(pred_labels.values) \n",
        "\n",
        "fig = go.Figure(layout=go.Layout(height=400, width=600))\n",
        "fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in categories]))\n",
        "fig.show()\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZafW1akIrLFM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}