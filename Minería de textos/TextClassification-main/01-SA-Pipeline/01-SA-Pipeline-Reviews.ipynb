{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/TeachingTextMining/TextClassification/blob/main/01-SA-Pipeline/01-SA-Pipeline-Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"NSF0oGu78Tcx"},"source":["## Entrenamiento y ejecución de un pipeline de clasificación textual\n","\n","La clasificación de textos consiste en, dado un texto, asignarle una entre varias categorías. Algunos ejemplos de esta tarea son:\n","\n","- dado un tweet, categorizar su connotación como positiva, negativa o neutra.\n","- dado un post de Facebook, clasificarlo como portador de un lenguaje ofensivo o no.  \n","\n","En la actividad exploraremos cómo crear un pipeline y entrenarlo para clasificar reviews de [IMDB](https://www.imdb.com/) sobre películas en las categorías \\[$positive$, $negative$\\]\n","\n","Puede encontrar más información sobre este problema en [Kaggle](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) y en [Large Movie Review Datase](http://ai.stanford.edu/~amaas/data/sentiment/). \n","\n","**Instrucciones:**\n","\n","- siga las indicaciones y comentarios en cada apartado.\n","\n","**Después de esta actividad nos habremos familiarizado con:**\n","- algunos tipos de características ampliamente utilizadas en la clasificación de textos. \n","- cómo construir un pipeline para la clasificación de textos utilizando [scikit-learn](https://scikit-learn.org/stable/).\n","- utilizar este pipeline para clasificar nuevos textos.\n","\n","**Requerimientos**\n","- python 3.6 - 3.8\n","- pandas\n","- plotly\n"]},{"cell_type":"markdown","metadata":{"id":"AwN4Y_Rr8waB"},"source":["<a name=\"sec:setup\"></a>\n","### Instalación de librerías e importación de dependencias.\n","\n","Para comenzar, es preciso instalar e incluir las librerías necesarias. En este caso, el entorno de Colab incluye las necesarias.\n","\n","Ejecute la siguiente casilla prestando atención a las explicaciones dadas en los comentarios."]},{"cell_type":"code","metadata":{"id":"aRnmup7KQC5G"},"source":["# reset environment\n","%reset -f\n","\n","#  para construir gráficas y realizar análisis exploratorio de los datos\n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","import plotly.express as px\n","\n","# para cargar datos y realizar pre-procesamiento básico\n","import pandas as pd\n","from collections import Counter\n","\n","# para pre-procesamiento del texto y extraer características\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from nltk.stem.snowball import EnglishStemmer\n","\n","# algoritmos de clasificación\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","\n","# para construir pipelines\n","from sklearn.pipeline import Pipeline\n","\n","# para evaluar los modelos \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n","from sklearn.utils.multiclass import unique_labels\n","\n","# para guardar el modelo\n","import pickle\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9RZOXOCU9WXq"},"source":["#### Definición de funciones y variables necesarias para el pre-procesamiento de datos\n","\n","Antes de definir el pipeline definiremos algunas variables útiles como el listado de stop words y funciones para cargar los datos, entrenar el modelo etc."]},{"cell_type":"code","metadata":{"id":"Jbiz7i6FPFfP"},"source":["#listado de stopwords. Este listado también se puede leer desde un fichero utilizando la función read_corpus\n","stop_words=['i','me','my','myself','we','our','ours','ourselves','you','your','yours','yourself','yourselves',\n","            'he','him','his','himself','she','her','hers','herself','it','its','itself','they','them','their',\n","            'theirs','themselves','what','which','who','whom','this','that','these','those','am','is','are',\n","            'was','were','be','been','being','have','has','had','having','do','does','did','doing','a','an',\n","            'the','and','but','if','or','because','as','until','while','of','at','by','for','with','about',\n","            'against','between','into','through','during','before','after','above','below','to','from','up',\n","            'down','in','out','on','off','over','under','again','further','then','once','here','there','when',\n","            'where','why','how','all','any','both','each','few','more','most','other','some','such','no','nor',\n","            'not','only','own','same','so','than','too','very','s','t','can','will','just','don','should','now', 'ever']\n","\n","\n","# función auxiliar. Se utiliza al obtener la representación mediante TF-IDF del texto pues en este caso\n","# se removerán las stop_words y se considerarán los \"stem\" en lugar de las palabrass\n","def english_stemmer(sentence):\n","    stemmer = EnglishStemmer()\n","    analyzer = CountVectorizer(binary=False, analyzer='word', stop_words=stop_words, ngram_range=(1, 1)).build_analyzer()\n","    return (stemmer.stem(word) for word in analyzer(sentence))\n","\n","\n","# guarda un pipeline entrenado\n","def save_model(model, modelName = \"pickle_model.pkl\"):\n","   pkl_filename = modelName\n","   with open(pkl_filename, 'wb') as file:\n","    pickle.dump(model, file)   \n","\n","\n","# carga un pipeline entrenado y guardado previamente\n","def load_model(rutaModelo = \"pickle_model.pkl\"):\n","  # Load from file\n","  with open(rutaModelo, 'rb') as file:\n","    pickle_model = pickle.load(file)\n","    return pickle_model \n","\n","\n","# función auxiliar para realizar predicciones con el modelo\n","def predict_model(model, data, pref='m'):\n","  \"\"\"\n","  data: list of the text to predict\n","  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\n","  \"\"\"\n","  res = {}\n","  scores = None\n","  labels = model.predict(data)\n","\n","  if hasattr(model, 'predict_proba'):\n","    scores = model.predict_proba(data)\n","  \n","    # empaquetar scores dentro de un diccionario que contiene labels, scores clase 1, scores clase 2, .... El nombre de la clase se normaliza a lowercase\n","    res = {f'scores_{pref}_{cls.lower()}':score for cls, score in zip(model.classes_, [col for col in scores.T])}\n","\n","  # añadir datos relativos a la predicción\n","  res[f'labels_{pref}'] = labels\n","\n","  # convertir a dataframe ordenando las columnas primero el label y luego los scores por clase, las clases ordenadas alfabéticamente.\n","  res = pd.DataFrame(res, columns=sorted(list(res.keys())))\n","\n","  return res\n","\n","\n","# función auxiliar que evalúa los resultados de una clasificación\n","def evaluate_model(y_true, y_pred, y_score=None, pos_label='positive'):\n","  \"\"\"\n","  \n","  \"\"\"\n","  print('==== Sumario de la clasificación ==== ')\n","  print(classification_report(y_true, y_pred))\n","\n","  print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_true, y_pred)))\n","\n","  # graficar matriz de confusión\n","  display_labels = sorted(unique_labels(y_true, y_pred), reverse=True)\n","  cm = confusion_matrix(y_true, y_pred, labels=display_labels)\n","\n","  z = cm[::-1]\n","  x = display_labels\n","  y =  x[::-1].copy()\n","  z_text = [[str(y) for y in x] for x in z]\n","\n","  fig_cm = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n","\n","  fig_cm.update_layout(\n","      height=400, width=400,\n","      showlegend=True,\n","      margin={'t':150, 'l':0},\n","      title={'text' : 'Matriz de Confusión', 'x':0.5, 'y':0.95, 'xanchor': 'center'},\n","      xaxis = {'title_text':'Valor Real', 'tickangle':45, 'side':'top'},\n","      yaxis = {'title_text':'Valor Predicho', 'tickmode':'linear'},\n","  )\n","  fig_cm.show()\n","\n","\n","  # curva roc (definido para clasificación binaria)\n","  fig_roc = None\n","  if y_score is not None:\n","    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=pos_label)\n","    fig_roc = px.area(\n","        x=fpr, y=tpr,\n","        title = f'Curva ROC (AUC={auc(fpr, tpr):.4f})',\n","        labels=dict(x='Ratio Falsos Positivos', y='Ratio Verdaderos Positivos'),\n","        width=400, height=400\n","    )\n","    fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","\n","    fig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","    fig_roc.update_xaxes(constrain='domain')\n","    \n","    fig_roc.show()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3UdRBoUg9tU9"},"source":["### Carga de datos y análisis exploratorio\n","\n","Antes de entrenar el pipeline, es necesario cargar los datos. Existen diferentes opciones, entre estas:\n","\n","- montar nuestra partición de Google Drive y leer un fichero desde esta.\n","\n","- leer los datos desde un fichero en una carpeta local.\n","\n","- leer los datos directamente de un URL.\n","\n","Ejecute la siguiente casilla prestando atención a las instrucciones adicionales en los comentarios.\n"]},{"cell_type":"code","metadata":{"id":"ZrxBtAfXUPPc"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n","\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n","#path = './sample_data/ejemplo_review_train.csv'\n","\n","# descomente la siguiente línea para leer datos desde un URL\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/01-SA-Pipeline/sample_data/ejemplo_review_train.csv'\n","\n","# leer los datos\n","data = pd.read_csv(path, sep=',')\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"he_d4nC4T1y4"},"source":["Una vez leídos los datos, ejecute la siguiente casilla para construir una gráfica que muestra la distribución de clases en el corpus. "]},{"cell_type":"code","metadata":{"id":"_YMzqSRUT150"},"source":["text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\n","class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\n","\n","# obtener algunas estadísticas sobre los datos\n","categories = sorted(data[class_col].unique(), reverse=False)\n","hist= Counter(data[class_col]) \n","print(f'Total de instancias -> {data.shape[0]}')\n","print('Distribución de clases:')\n","for item in sorted(hist.items(), key=lambda x: x[0]): print(f'    {item[0]}: {round(item[1]/len(data[class_col]), 3)}')\n","\n","print(f'Categorías -> {categories}')\n","print(f'Comentario de ejemplo -> {data[text_col][0]}')\n","print(f'Categoría del comentario -> {data[class_col][0]}')\n","\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in categories]))\n","fig.show()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GnyOSf-36R5d"},"source":["Finalmente, ejecute la siguiente casilla para crear los conjuntos de entrenamiento y validación que se utilizarán para entrenar y validar los modelos."]},{"cell_type":"code","metadata":{"id":"-xkZtv4T6SRM"},"source":["# obtener conjuntos de entrenamiento (90%) y validación (10%)\n","seed = 0  # fijar random_state para reproducibilidad\n","train, val = train_test_split(data, test_size=.1, stratify=data[class_col], random_state=seed)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tYXr8ivvucB6"},"source":["### Creación de un pipeline para la clasificación de textos\n","\n","Para construir el pipeline, utilizaremos la clase Pipeline de sklean. Esta permite encadenar los diferentes pasos, por ejemplo, algoritmos de extracción de características y un clasificador. Por ejemplo, para obtener un pipeline que comprende CountVectorizer, seguido de TfidfTransformer y un Support Vector Machine como clasificador, se utilizaría esta sentencia:\n","\n","~~~ \n","Pipeline([\n","        ('dataVect', CountVectorizer(analyzer=english_stemmer)),\n","        ('tfidf', TfidfTransformer(smooth_idf=True, use_idf=True)),\n","        (classifier, SVC(probability=True) )\n","     ])\n","~~~\n","\n","Para tener mayor flexibilidad si se desean probar varios clasificadores, podría construirse el pipeline sin clasificador, incluyendo este con posterioridad. Este será el enfoque que seguiremos en la actividad.\n","\n","Ejecute la siguiente casilla para definir una función que construye un pipeline con las características antes mencionadas.\n"]},{"cell_type":"code","metadata":{"id":"Ei1DHRhRucYZ"},"source":["def preprocess_pipeline():\n","    return Pipeline([\n","        ('dataVect', CountVectorizer(analyzer=english_stemmer)),\n","        ('tfidf', TfidfTransformer(smooth_idf=True, use_idf=True)),\n","     ])\n","    \n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bozyrzk8-UCH"},"source":["### Entrenamiento del modelo\n","\n","Ejecute la siguiente casilla que integra todas las funciones definidas para construir el pipeline, entrenarlo y guardarlo para su posterior uso.\n"]},{"cell_type":"code","metadata":{"id":"E5Sp_8RVTLqA"},"source":["# crear el pipeline (solo incluyendo los pasos de pre-procesamiento)\n","model = preprocess_pipeline()\n","\n","# crear el clasificador y añadirlo al model. Puede probar diferentes clasificadores\n","# classifier = MultinomialNB()\n","# classifier = DecisionTreeClassifier()\n","classifier = SVC(probability=True)\n","\n","model.steps.append(('classifier', classifier))\n","\n","# obtener conjuntos de entrenamiento (90%) y validación (10%)\n","seed = 0    # fijar random_state para reproducibilidad\n","train, val = train_test_split(data, test_size=.1, stratify=data[class_col], random_state=seed)\n","\n","# entrenar el modelo\n","model.fit(train[text_col], train[class_col])\n","\n","# guardar el modelo\n","save_model(model)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tzMUiKT28Rrs"},"source":["### Evaluación del modelo\n","Luego de entrenado el modelo, podemos evaluar su desempeño en los conjuntos de entrenamiento y validación.\n","\n","Ejecute la siguiente casilla para evaluar el modelo en el conjunto de entrenamiento."]},{"cell_type":"code","metadata":{"id":"E0bKIO23TmuW"},"source":["# predecir y evaluar el modelo en el conjunto de entrenamiento\n","print('==== Evaluación conjunto de entrenamiento ====')\n","data = train\n","true_labels = data[class_col]\n","\n","m_pred = predict_model(model, data[text_col].to_list(), pref='m')\n","\n","# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\n","evaluate_model(true_labels, m_pred['labels_m'], m_pred['scores_m_positive'], 'positive')  \n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1jv7xRTa0GaN"},"source":["Ejecute la siguiente casilla para evaluar el modelo en el conjunto de validación. Compare los resultados."]},{"cell_type":"code","metadata":{"id":"I9vNzF3D0GpU"},"source":["# predecir y evaluar el modelo en el conjunto de validación\n","print('==== Evaluación conjunto de validación ====')\n","data = val\n","true_labels = data[class_col]\n","\n","m_pred = predict_model(model, data[text_col].to_list(), pref='m')\n","\n","# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\n","evaluate_model(true_labels, m_pred['labels_m'], m_pred['scores_m_positive'], 'positive')\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EKPISmflTW3b"},"source":["## Predicción de nuevos datos\n","\n","Una vez entrenado el modelo, podemos evaluar su rendimiento en datos no utilizados durante el entrenamiento o emplearlo para predecir nuevas instancias. En cualquier caso, se debe cuidar realizar los pasos de pre-procesamiento necesarios según el caso. En el ejemplo, utilizaremos la porción de prueba preparada inicialmente.\n","\n","**Notar que**:\n","-  se cargará el modelo previamente entrenado y guardado, estableciendo las configuraciones pertinentes.\n","\n","- si disponemos de un modelo guardado, podremos ejecutar directamente esta parte del cuaderno. Sin embargo, será necesario al menos ejecutar previamente la sección [Instalación de librerías...](#sec:setup)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"g2mEFOG-ddAQ"},"source":["### Instanciar modelo pre-entrenado\n","\n","Para predecir nuevas instancias es preciso cargar el modelo previamente entrenado. Esto dependerá del formato en el que se exportó el modelo, pero en general se requieren dos elementos: la estructura del modelo y los pesos. \n","\n","Ejecute la siguiente casilla para cargar el modelo."]},{"cell_type":"code","metadata":{"id":"NsUS0WEQddNQ"},"source":["# cargar pipeline entrenado\n","model = load_model()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rQALJSVbdus2"},"source":["### Predecir nuevos datos\n","\n","Con el modelo cargado, es posible utilizarlo para analizar nuevos datos. \n","\n","Ejecute las siguientes casillas para:\n","\n","(a) categorizar un texto de muestra.\n","\n","(b) cargar nuevos datos, categorizarlos y mostrar algunas estadísticas sobre el corpus."]},{"cell_type":"code","metadata":{"id":"EsWQHd2pdu03"},"source":["# ejemplo de texto a clasificar en formato [text 1, text 2, ..., text n]\n","text = ['Brian De Palma\\'s undeniable virtuosity can\\'t really camouflage the fact that his plot here is a thinly disguised\\\n","        \\\"Psycho\\\" carbon copy, but he does provide a genuinely terrifying climax. His \"Blow Out\", made the next year, was an improvement.']\n","\n","# predecir los nuevos datos\n","m_pred = predict_model(model, text, pref='m')\n","\n","# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\n","pred_labels = m_pred['labels_m'].values[0]\n","pred_proba = m_pred['scores_m_positive'].values[0]\n","\n","print(f'La categoría del review es -> {pred_labels}')\n","print(f'El score asignado a la clase positiva es -> {pred_proba:.2f}')\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zj3Uokajeybr"},"source":["También podemos predecir nuevos datos cargados desde un fichero. \n","\n","Ejecute la siguiente casilla, descomentando las instrucciones necesarias según sea el caso."]},{"cell_type":"code","metadata":{"id":"E0pEVuSzQNbI"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n","\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n","#path = './sample_data/ejemplo_review_train.csv'\n","\n","# descomente la siguiente línea para leer datos desde un URL\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/01-SA-Pipeline/sample_data/ejemplo_review_test.csv'\n","\n","# leer los datos\n","new_data = pd.read_csv(path, sep=',')\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FkLCCX-7QBU6"},"source":["Ejecute la siguiente celda para predecir los datos y mostrar algunas estadísticas sobre el análisis realizado."]},{"cell_type":"code","metadata":{"id":"U3sKmB36s5ma"},"source":["# predecir los datos de prueba\n","text_col = 'Phrase'\n","m_pred = predict_model(model, new_data[text_col].to_list(), pref='m')\n","pred_labels = m_pred['labels_m']\n","\n","# obtener algunas estadísticas sobre la predicción en el conjunto de pruebas\n","categories = sorted(pred_labels.unique(), reverse=False)\n","hist = Counter(pred_labels.values) \n","\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in categories]))\n","fig.show()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]}]}